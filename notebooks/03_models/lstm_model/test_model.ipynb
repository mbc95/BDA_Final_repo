{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 20000)\n",
    "pd.options.mode.chained_assignment = None #Ignore Error: SettingWithCopyWarning\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Flatten, Dense, Lambda, Reshape, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import mse, accuracy\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../data/preprocessed/cleaned_data_v7.csv', delimiter=\",\")\n",
    "df = pd.read_csv('../data/preprocessed/cleaned_data_agg_v1.csv', delimiter=\",\")\n",
    "\n",
    "key_list = df.keys().tolist()\n",
    "\n",
    "for x in range(len(key_list)):\n",
    "    if not df.columns[x] == \"datum\":\n",
    "        if not df.columns[x] == \"container_id\":\n",
    "            df = df.astype({key_list[x]: \"float32\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete unwanted data; cast datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"height_in_cm\"])\n",
    "\n",
    "# set date as index ancd convert to float\n",
    "df['datum'] = pd.to_datetime(df['datum'])\n",
    "df = df.set_index(df['datum'])\n",
    "df = df.sort_index()\n",
    "df['datum_float'] = df['datum'].values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: (19142, 25)\n",
      "Test Dataset: (7539, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-4a93c0fbbe20>:2: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  training_set = df['2020-05-09 00:00:00':'2021-01-29 23:59:59']\n",
      "<ipython-input-10-4a93c0fbbe20>:3: FutureWarning: Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is deprecated and will raise a KeyError in a future Version.\n",
      "  test_set  = df['2021-01-30 00:00:00':]\n"
     ]
    }
   ],
   "source": [
    "# create train test partition\n",
    "training_set = df['2020-05-09 00:00:00':'2021-01-29 23:59:59']\n",
    "test_set  = df['2021-01-30 00:00:00':]\n",
    "print('Train Dataset:',training_set.shape)\n",
    "print('Test Dataset:',test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>container_id</th>\n",
       "      <th>temperatur_in_grad</th>\n",
       "      <th>aussentemperatur</th>\n",
       "      <th>niederschlag_in_mm</th>\n",
       "      <th>ist_industriegebiet</th>\n",
       "      <th>ist_wohngebiet</th>\n",
       "      <th>ist_feiertag</th>\n",
       "      <th>datum</th>\n",
       "      <th>sekunde</th>\n",
       "      <th>minute</th>\n",
       "      <th>stunde</th>\n",
       "      <th>wochentag</th>\n",
       "      <th>kalenderwoche</th>\n",
       "      <th>monat</th>\n",
       "      <th>jahr</th>\n",
       "      <th>farbe_brown</th>\n",
       "      <th>farbe_green</th>\n",
       "      <th>farbe_white</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>hight_delta</th>\n",
       "      <th>ist_ferien</th>\n",
       "      <th>laengengrad</th>\n",
       "      <th>breitengrad</th>\n",
       "      <th>datum_float</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-09 19:40:46.486563</th>\n",
       "      <td>70.0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-09 19:40:46.486563</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.589050e+12</td>\n",
       "      <td>50399600.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.119270</td>\n",
       "      <td>8.770680</td>\n",
       "      <td>1.589053e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-09 21:22:06.657404</th>\n",
       "      <td>57.0</td>\n",
       "      <td>20.904762</td>\n",
       "      <td>8.366667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-09 21:22:06.657404</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.589050e+12</td>\n",
       "      <td>3599860.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.123043</td>\n",
       "      <td>8.765538</td>\n",
       "      <td>1.589059e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-09 22:42:23.140342</th>\n",
       "      <td>25.0</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>23.118181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-09 22:42:23.140342</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.589060e+12</td>\n",
       "      <td>7199647.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.130257</td>\n",
       "      <td>8.709095</td>\n",
       "      <td>1.589064e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-09 22:47:38.461644</th>\n",
       "      <td>71.0</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>4.095000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-09 22:47:38.461644</td>\n",
       "      <td>38.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.589060e+12</td>\n",
       "      <td>3599811.0</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.125187</td>\n",
       "      <td>8.710195</td>\n",
       "      <td>1.589064e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-09 22:49:15.517636</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.523809</td>\n",
       "      <td>1.509524</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-09 22:49:15.517636</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.589060e+12</td>\n",
       "      <td>3599771.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.134075</td>\n",
       "      <td>8.707200</td>\n",
       "      <td>1.589065e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-29 23:47:57.755353</th>\n",
       "      <td>37.0</td>\n",
       "      <td>7.842105</td>\n",
       "      <td>9.321053</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-29 23:47:57.755353</td>\n",
       "      <td>57.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611960e+12</td>\n",
       "      <td>3599852.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.129505</td>\n",
       "      <td>8.706566</td>\n",
       "      <td>1.611964e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-29 23:53:48.114059</th>\n",
       "      <td>34.0</td>\n",
       "      <td>11.608696</td>\n",
       "      <td>11.126087</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-29 23:53:48.114059</td>\n",
       "      <td>48.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611960e+12</td>\n",
       "      <td>3599919.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.128185</td>\n",
       "      <td>8.704522</td>\n",
       "      <td>1.611964e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-29 23:55:40.509137</th>\n",
       "      <td>55.0</td>\n",
       "      <td>14.055555</td>\n",
       "      <td>5.477778</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-29 23:55:40.509137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.611960e+12</td>\n",
       "      <td>3599861.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.133209</td>\n",
       "      <td>8.697432</td>\n",
       "      <td>1.611965e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-29 23:56:00.484970</th>\n",
       "      <td>58.0</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>6.020000</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-29 23:56:00.484970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.611960e+12</td>\n",
       "      <td>3599839.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.129505</td>\n",
       "      <td>8.706566</td>\n",
       "      <td>1.611965e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-29 23:58:02.169932</th>\n",
       "      <td>35.0</td>\n",
       "      <td>6.217391</td>\n",
       "      <td>2.665217</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-29 23:58:02.169932</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611960e+12</td>\n",
       "      <td>3599950.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.123940</td>\n",
       "      <td>8.762620</td>\n",
       "      <td>1.611965e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19142 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            container_id  temperatur_in_grad  \\\n",
       "datum                                                          \n",
       "2020-05-09 19:40:46.486563          70.0           17.500000   \n",
       "2020-05-09 21:22:06.657404          57.0           20.904762   \n",
       "2020-05-09 22:42:23.140342          25.0           18.181818   \n",
       "2020-05-09 22:47:38.461644          71.0           14.800000   \n",
       "2020-05-09 22:49:15.517636           6.0           14.523809   \n",
       "...                                  ...                 ...   \n",
       "2021-01-29 23:47:57.755353          37.0            7.842105   \n",
       "2021-01-29 23:53:48.114059          34.0           11.608696   \n",
       "2021-01-29 23:55:40.509137          55.0           14.055555   \n",
       "2021-01-29 23:56:00.484970          58.0           13.300000   \n",
       "2021-01-29 23:58:02.169932          35.0            6.217391   \n",
       "\n",
       "                            aussentemperatur  niederschlag_in_mm  \\\n",
       "datum                                                              \n",
       "2020-05-09 19:40:46.486563         18.950001                 0.0   \n",
       "2020-05-09 21:22:06.657404          8.366667                 0.6   \n",
       "2020-05-09 22:42:23.140342         23.118181                 0.0   \n",
       "2020-05-09 22:47:38.461644          4.095000                 0.6   \n",
       "2020-05-09 22:49:15.517636          1.509524                 0.6   \n",
       "...                                      ...                 ...   \n",
       "2021-01-29 23:47:57.755353          9.321053                 5.5   \n",
       "2021-01-29 23:53:48.114059         11.126087                 9.2   \n",
       "2021-01-29 23:55:40.509137          5.477778                 8.3   \n",
       "2021-01-29 23:56:00.484970          6.020000                 8.3   \n",
       "2021-01-29 23:58:02.169932          2.665217                 9.2   \n",
       "\n",
       "                            ist_industriegebiet  ist_wohngebiet  ist_feiertag  \\\n",
       "datum                                                                           \n",
       "2020-05-09 19:40:46.486563                  1.0             0.0           0.0   \n",
       "2020-05-09 21:22:06.657404                  1.0             0.0           0.0   \n",
       "2020-05-09 22:42:23.140342                  0.0             1.0           0.0   \n",
       "2020-05-09 22:47:38.461644                  0.0             1.0           0.0   \n",
       "2020-05-09 22:49:15.517636                  0.0             1.0           0.0   \n",
       "...                                         ...             ...           ...   \n",
       "2021-01-29 23:47:57.755353                  0.0             1.0           0.0   \n",
       "2021-01-29 23:53:48.114059                  0.0             1.0           0.0   \n",
       "2021-01-29 23:55:40.509137                  0.0             1.0           0.0   \n",
       "2021-01-29 23:56:00.484970                  0.0             1.0           0.0   \n",
       "2021-01-29 23:58:02.169932                  1.0             0.0           0.0   \n",
       "\n",
       "                                                datum  sekunde  minute  \\\n",
       "datum                                                                    \n",
       "2020-05-09 19:40:46.486563 2020-05-09 19:40:46.486563     46.0    40.0   \n",
       "2020-05-09 21:22:06.657404 2020-05-09 21:22:06.657404      6.0    22.0   \n",
       "2020-05-09 22:42:23.140342 2020-05-09 22:42:23.140342     23.0    42.0   \n",
       "2020-05-09 22:47:38.461644 2020-05-09 22:47:38.461644     38.0    47.0   \n",
       "2020-05-09 22:49:15.517636 2020-05-09 22:49:15.517636     15.0    49.0   \n",
       "...                                               ...      ...     ...   \n",
       "2021-01-29 23:47:57.755353 2021-01-29 23:47:57.755353     57.0    47.0   \n",
       "2021-01-29 23:53:48.114059 2021-01-29 23:53:48.114059     48.0    53.0   \n",
       "2021-01-29 23:55:40.509137 2021-01-29 23:55:40.509137     40.0    55.0   \n",
       "2021-01-29 23:56:00.484970 2021-01-29 23:56:00.484970      0.0    56.0   \n",
       "2021-01-29 23:58:02.169932 2021-01-29 23:58:02.169932      2.0    58.0   \n",
       "\n",
       "                            stunde  wochentag  kalenderwoche  monat    jahr  \\\n",
       "datum                                                                         \n",
       "2020-05-09 19:40:46.486563    19.0        5.0           19.0    5.0  2020.0   \n",
       "2020-05-09 21:22:06.657404    21.0        5.0           19.0    5.0  2020.0   \n",
       "2020-05-09 22:42:23.140342    22.0        5.0           19.0    5.0  2020.0   \n",
       "2020-05-09 22:47:38.461644    22.0        5.0           19.0    5.0  2020.0   \n",
       "2020-05-09 22:49:15.517636    22.0        5.0           19.0    5.0  2020.0   \n",
       "...                            ...        ...            ...    ...     ...   \n",
       "2021-01-29 23:47:57.755353    23.0        4.0            4.0    1.0  2021.0   \n",
       "2021-01-29 23:53:48.114059    23.0        4.0            4.0    1.0  2021.0   \n",
       "2021-01-29 23:55:40.509137    23.0        4.0            4.0    1.0  2021.0   \n",
       "2021-01-29 23:56:00.484970    23.0        4.0            4.0    1.0  2021.0   \n",
       "2021-01-29 23:58:02.169932    23.0        4.0            4.0    1.0  2021.0   \n",
       "\n",
       "                            farbe_brown  farbe_green  farbe_white  \\\n",
       "datum                                                               \n",
       "2020-05-09 19:40:46.486563          0.0          1.0          0.0   \n",
       "2020-05-09 21:22:06.657404          0.0          1.0          0.0   \n",
       "2020-05-09 22:42:23.140342          0.0          0.0          1.0   \n",
       "2020-05-09 22:47:38.461644          1.0          0.0          0.0   \n",
       "2020-05-09 22:49:15.517636          1.0          0.0          0.0   \n",
       "...                                 ...          ...          ...   \n",
       "2021-01-29 23:47:57.755353          1.0          0.0          0.0   \n",
       "2021-01-29 23:53:48.114059          0.0          1.0          0.0   \n",
       "2021-01-29 23:55:40.509137          0.0          0.0          1.0   \n",
       "2021-01-29 23:56:00.484970          0.0          0.0          1.0   \n",
       "2021-01-29 23:58:02.169932          0.0          1.0          0.0   \n",
       "\n",
       "                               unix_time  time_delta  hight_delta  ist_ferien  \\\n",
       "datum                                                                           \n",
       "2020-05-09 19:40:46.486563  1.589050e+12  50399600.0        -22.0         0.0   \n",
       "2020-05-09 21:22:06.657404  1.589050e+12   3599860.0       -180.0         0.0   \n",
       "2020-05-09 22:42:23.140342  1.589060e+12   7199647.0        -24.0         0.0   \n",
       "2020-05-09 22:47:38.461644  1.589060e+12   3599811.0       -106.0         0.0   \n",
       "2020-05-09 22:49:15.517636  1.589060e+12   3599771.0         -2.0         0.0   \n",
       "...                                  ...         ...          ...         ...   \n",
       "2021-01-29 23:47:57.755353  1.611960e+12   3599852.0        -18.0         0.0   \n",
       "2021-01-29 23:53:48.114059  1.611960e+12   3599919.0        -20.0         0.0   \n",
       "2021-01-29 23:55:40.509137  1.611960e+12   3599861.0        -46.0         0.0   \n",
       "2021-01-29 23:56:00.484970  1.611960e+12   3599839.0        -12.0         0.0   \n",
       "2021-01-29 23:58:02.169932  1.611960e+12   3599950.0         -8.0         0.0   \n",
       "\n",
       "                            laengengrad  breitengrad   datum_float  \n",
       "datum                                                               \n",
       "2020-05-09 19:40:46.486563    50.119270     8.770680  1.589053e+18  \n",
       "2020-05-09 21:22:06.657404    50.123043     8.765538  1.589059e+18  \n",
       "2020-05-09 22:42:23.140342    50.130257     8.709095  1.589064e+18  \n",
       "2020-05-09 22:47:38.461644    50.125187     8.710195  1.589064e+18  \n",
       "2020-05-09 22:49:15.517636    50.134075     8.707200  1.589065e+18  \n",
       "...                                 ...          ...           ...  \n",
       "2021-01-29 23:47:57.755353    50.129505     8.706566  1.611964e+18  \n",
       "2021-01-29 23:53:48.114059    50.128185     8.704522  1.611964e+18  \n",
       "2021-01-29 23:55:40.509137    50.133209     8.697432  1.611965e+18  \n",
       "2021-01-29 23:56:00.484970    50.129505     8.706566  1.611965e+18  \n",
       "2021-01-29 23:58:02.169932    50.123940     8.762620  1.611965e+18  \n",
       "\n",
       "[19142 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f\n",
    "#https://analyticsindiamag.com/hands-on-guide-to-lstm-recurrent-neural-network-for-stock-market-prediction/\n",
    "# Feature Scaling\n",
    "\n",
    "# ****************** START TUNING *************\n",
    "timelag = 3 #10\n",
    "epochs_number = 1000 #10\n",
    "batch_size_number = 32 #32\n",
    "container_number = 1\n",
    "\n",
    "# ****************** END TUNING *************\n",
    "\n",
    "training_set = training_set[training_set['container_id']==container_number]\n",
    "train_set = training_set.iloc[:, 20:21].values\n",
    "\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(train_set)\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(timelag, len(training_set)-1):\n",
    "    X_train.append(training_set_scaled[i-timelag:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0]) \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "       1.        , 1.        , 0.9830508 , 1.        , 0.9830508 ,\n",
       "       0.7966102 , 0.86440676, 0.7118644 , 0.7118644 , 0.91525424,\n",
       "       0.9322034 , 0.6949153 , 0.89830506, 0.88135594, 0.9322034 ,\n",
       "       0.6779661 , 0.8135593 , 0.86440676, 0.779661  , 0.91525424,\n",
       "       0.88135594, 0.62711865, 0.7627119 , 0.779661  , 0.88135594,\n",
       "       0.7966102 , 0.7627119 , 0.84745765, 0.7966102 , 0.779661  ,\n",
       "       0.86440676, 0.7966102 , 0.89830506, 0.7966102 , 0.9322034 ,\n",
       "       0.84745765, 0.9322034 , 0.88135594, 0.7966102 , 0.9830508 ,\n",
       "       0.9661017 , 1.        , 0.9322034 , 0.89830506, 0.8135593 ,\n",
       "       0.8305085 , 0.84745765, 0.779661  , 0.86440676, 0.779661  ,\n",
       "       0.89830506, 0.91525424, 0.91525424, 0.8305085 , 0.779661  ,\n",
       "       0.5762712 , 0.6949153 , 0.89830506, 0.9491525 , 0.8135593 ,\n",
       "       0.84745765, 0.89830506, 0.86440676, 0.7118644 , 0.84745765,\n",
       "       0.8305085 , 0.8305085 , 0.89830506, 0.84745765, 0.8305085 ,\n",
       "       0.8135593 , 0.9322034 , 0.91525424, 0.7457627 , 0.8305085 ,\n",
       "       0.8135593 , 0.9322034 , 0.7966102 , 0.9491525 , 0.9491525 ,\n",
       "       0.8135593 , 0.84745765, 0.88135594, 0.9322034 , 0.7966102 ,\n",
       "       0.84745765, 0.84745765, 0.84745765, 0.88135594, 0.8135593 ,\n",
       "       0.89830506, 0.6779661 , 0.86440676, 0.86440676, 0.9322034 ,\n",
       "       0.7966102 , 0.779661  , 0.9491525 , 0.89830506, 0.9322034 ,\n",
       "       0.9322034 , 0.9661017 , 0.91525424, 1.        , 1.        ,\n",
       "       0.9830508 , 0.86440676, 0.7966102 , 1.        , 0.9830508 ,\n",
       "       0.84745765, 0.86440676, 0.7288135 , 0.779661  , 0.84745765,\n",
       "       0.88135594, 0.8305085 , 0.86440676, 0.88135594, 0.88135594,\n",
       "       0.9491525 , 0.9491525 , 0.779661  , 0.84745765, 0.7457627 ,\n",
       "       0.84745765, 0.8135593 , 0.9491525 , 0.91525424, 0.6949153 ,\n",
       "       0.7288135 , 0.        , 0.9661017 , 0.8135593 , 0.7457627 ,\n",
       "       0.9491525 , 0.8305085 , 0.8305085 , 0.91525424, 0.84745765,\n",
       "       0.86440676, 0.84745765, 0.9830508 , 0.8305085 , 0.91525424,\n",
       "       0.9661017 , 0.91525424, 0.9830508 , 0.8305085 , 0.7457627 ,\n",
       "       0.9322034 , 0.779661  , 0.84745765, 0.779661  , 0.84745765,\n",
       "       0.84745765, 0.7966102 , 0.88135594, 0.7118644 , 0.9491525 ,\n",
       "       0.6779661 , 0.62711865, 0.84745765, 0.9830508 , 0.89830506,\n",
       "       0.84745765, 0.89830506, 0.66101694, 0.7457627 , 0.779661  ,\n",
       "       0.84745765, 0.7966102 , 0.7288135 , 0.9491525 , 0.86440676,\n",
       "       0.86440676, 0.88135594, 0.86440676, 0.89830506, 0.84745765,\n",
       "       0.9491525 , 0.86440676, 1.        , 0.9322034 , 0.9830508 ,\n",
       "       0.91525424, 0.7627119 , 0.86440676, 0.779661  , 0.8305085 ,\n",
       "       0.84745765, 0.91525424, 0.8305085 , 0.86440676, 0.86440676,\n",
       "       0.88135594, 0.84745765, 0.91525424, 0.91525424, 0.7966102 ,\n",
       "       0.88135594, 0.9830508 , 0.9830508 , 1.        , 0.9661017 ,\n",
       "       1.        , 0.88135594, 0.4745763 , 0.89830506, 0.89830506,\n",
       "       0.91525424, 0.7627119 , 0.89830506, 0.91525424, 0.84745765,\n",
       "       0.8135593 , 0.8135593 , 0.61016953, 0.7118644 , 0.89830506,\n",
       "       0.91525424, 0.84745765, 0.779661  , 0.59322035, 0.66101694,\n",
       "       0.8305085 , 0.7457627 , 0.86440676, 0.7966102 , 0.7457627 ,\n",
       "       0.86440676, 1.        , 0.84745765, 0.9830508 , 0.84745765,\n",
       "       0.61016953, 0.91525424, 0.86440676, 0.7118644 , 0.84745765,\n",
       "       0.8305085 , 0.7627119 , 0.8305085 , 0.88135594, 0.66101694,\n",
       "       0.7627119 , 0.9830508 , 0.9491525 , 0.9830508 , 0.7118644 ,\n",
       "       0.88135594, 0.88135594, 0.91525424, 0.8305085 , 0.9661017 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "#first callback method\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, verbose=1,\n",
    "#patience=25, min_lr=0.0000001, min_delta=0.0001)\n",
    "#default value lr = 0.001\n",
    "#callbacks = [reduce_lr]\n",
    "\n",
    "# Second callback mehod\n",
    "#es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "173/173 [==============================] - 51s 20ms/step - loss: 0.3129\n",
      "Epoch 2/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0287\n",
      "Epoch 3/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0269\n",
      "Epoch 4/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0256\n",
      "Epoch 5/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0307\n",
      "Epoch 6/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0288: 0\n",
      "Epoch 7/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0228\n",
      "Epoch 8/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0274: 0s - los\n",
      "Epoch 9/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0266\n",
      "Epoch 10/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0256\n",
      "Epoch 11/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0288: 0s - lo\n",
      "Epoch 12/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0231\n",
      "Epoch 13/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0249\n",
      "Epoch 14/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0228\n",
      "Epoch 15/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0258\n",
      "Epoch 16/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0253\n",
      "Epoch 17/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0229\n",
      "Epoch 18/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0244\n",
      "Epoch 19/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0270\n",
      "Epoch 20/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0233\n",
      "Epoch 21/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0278\n",
      "Epoch 22/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0225\n",
      "Epoch 23/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0218\n",
      "Epoch 24/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0219\n",
      "Epoch 25/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0250\n",
      "Epoch 26/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0228\n",
      "Epoch 27/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0237\n",
      "Epoch 28/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0256\n",
      "Epoch 29/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0219\n",
      "Epoch 30/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0231\n",
      "Epoch 31/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0238\n",
      "Epoch 32/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0240\n",
      "Epoch 33/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0223\n",
      "Epoch 34/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0235\n",
      "Epoch 35/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0213\n",
      "Epoch 36/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0245\n",
      "Epoch 37/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0266\n",
      "Epoch 38/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0191\n",
      "Epoch 39/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0213\n",
      "Epoch 40/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0256\n",
      "Epoch 41/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0243\n",
      "Epoch 42/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0222\n",
      "Epoch 43/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0192\n",
      "Epoch 44/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0233\n",
      "Epoch 45/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0246\n",
      "Epoch 46/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0231\n",
      "Epoch 47/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0217\n",
      "Epoch 48/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0219\n",
      "Epoch 49/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0222\n",
      "Epoch 50/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0225\n",
      "Epoch 51/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0220\n",
      "Epoch 52/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0229\n",
      "Epoch 53/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0212\n",
      "Epoch 54/1000\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.023 - 3s 18ms/step - loss: 0.0230\n",
      "Epoch 55/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0196\n",
      "Epoch 56/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0239\n",
      "Epoch 57/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0222\n",
      "Epoch 58/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0228\n",
      "Epoch 59/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0199\n",
      "Epoch 60/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0233\n",
      "Epoch 61/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0196\n",
      "Epoch 62/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0226\n",
      "Epoch 63/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0229\n",
      "Epoch 64/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0227\n",
      "Epoch 65/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0240\n",
      "Epoch 66/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0193\n",
      "Epoch 67/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0230\n",
      "Epoch 68/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0225\n",
      "Epoch 69/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0210\n",
      "Epoch 70/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0228\n",
      "Epoch 71/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0233\n",
      "Epoch 72/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0235\n",
      "Epoch 73/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0227\n",
      "Epoch 74/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0222\n",
      "Epoch 75/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0221\n",
      "Epoch 76/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0250\n",
      "Epoch 77/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0213\n",
      "Epoch 78/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0219\n",
      "Epoch 79/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0225\n",
      "Epoch 80/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0211\n",
      "Epoch 81/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0211\n",
      "Epoch 82/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0196\n",
      "Epoch 83/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0207\n",
      "Epoch 84/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0198\n",
      "Epoch 85/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0238\n",
      "Epoch 86/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0237\n",
      "Epoch 87/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0216\n",
      "Epoch 88/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0206: 0s \n",
      "Epoch 89/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0231\n",
      "Epoch 90/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0244\n",
      "Epoch 91/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0224\n",
      "Epoch 92/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0217\n",
      "Epoch 93/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0201\n",
      "Epoch 94/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0254\n",
      "Epoch 95/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0226\n",
      "Epoch 96/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0201\n",
      "Epoch 97/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0207\n",
      "Epoch 98/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0241\n",
      "Epoch 99/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0223\n",
      "Epoch 100/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0204\n",
      "Epoch 101/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0211\n",
      "Epoch 102/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0190\n",
      "Epoch 103/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0237\n",
      "Epoch 104/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0202:\n",
      "Epoch 105/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0210\n",
      "Epoch 106/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0217\n",
      "Epoch 107/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0211\n",
      "Epoch 108/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0221\n",
      "Epoch 109/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0225\n",
      "Epoch 110/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0190\n",
      "Epoch 111/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0235\n",
      "Epoch 112/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0259\n",
      "Epoch 113/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0176\n",
      "Epoch 114/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0199\n",
      "Epoch 115/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0185\n",
      "Epoch 116/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0216\n",
      "Epoch 117/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0223\n",
      "Epoch 118/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0242\n",
      "Epoch 119/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0220\n",
      "Epoch 120/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0201\n",
      "Epoch 121/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0231\n",
      "Epoch 122/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0223\n",
      "Epoch 123/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0217\n",
      "Epoch 124/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0210\n",
      "Epoch 125/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0228\n",
      "Epoch 126/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0241\n",
      "Epoch 127/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0238\n",
      "Epoch 128/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0200\n",
      "Epoch 129/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0203\n",
      "Epoch 130/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0203\n",
      "Epoch 131/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0221\n",
      "Epoch 132/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0226\n",
      "Epoch 133/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0225\n",
      "Epoch 134/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0202\n",
      "Epoch 135/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0270\n",
      "Epoch 136/1000\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0237\n",
      "Epoch 137/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0221\n",
      "Epoch 138/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0203\n",
      "Epoch 139/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0211\n",
      "Epoch 140/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0218\n",
      "Epoch 141/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0210\n",
      "Epoch 142/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0214\n",
      "Epoch 143/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0193\n",
      "Epoch 144/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0243: 0s - loss\n",
      "Epoch 145/1000\n",
      "173/173 [==============================] - 4s 24ms/step - loss: 0.0220\n",
      "Epoch 146/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0206: 0s - loss: 0.020\n",
      "Epoch 147/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0204\n",
      "Epoch 148/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0214: 0s - loss:\n",
      "Epoch 149/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0218\n",
      "Epoch 150/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0223\n",
      "Epoch 151/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0239\n",
      "Epoch 152/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0264\n",
      "Epoch 153/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0223\n",
      "Epoch 154/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0188\n",
      "Epoch 155/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0191\n",
      "Epoch 156/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0227\n",
      "Epoch 157/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0224: 0s \n",
      "Epoch 158/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0198\n",
      "Epoch 159/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0228: 0s \n",
      "Epoch 160/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0226\n",
      "Epoch 161/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0231:\n",
      "Epoch 162/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0227\n",
      "Epoch 163/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0192:\n",
      "Epoch 164/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0223: 0s - loss:\n",
      "Epoch 165/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0202\n",
      "Epoch 166/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0226\n",
      "Epoch 167/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0212\n",
      "Epoch 168/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0236\n",
      "Epoch 169/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0184\n",
      "Epoch 170/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0220\n",
      "Epoch 171/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0214: 1s  - ETA: 0s -  - ETA: 0s - loss: 0.\n",
      "Epoch 172/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0230\n",
      "Epoch 173/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0199\n",
      "Epoch 174/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0217\n",
      "Epoch 175/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0226: 0s - lo\n",
      "Epoch 176/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0190\n",
      "Epoch 177/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0214: 1s -  - ETA: 0s - loss: 0.02 - ETA: 0s - los\n",
      "Epoch 178/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0213\n",
      "Epoch 179/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0204\n",
      "Epoch 180/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0202\n",
      "Epoch 181/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0218\n",
      "Epoch 182/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0241\n",
      "Epoch 183/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0199: 0s - los\n",
      "Epoch 184/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0247\n",
      "Epoch 185/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0206\n",
      "Epoch 186/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0199\n",
      "Epoch 187/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0213: 1s -  - ETA: 0s \n",
      "Epoch 188/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0230: 2s\n",
      "Epoch 189/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0232: 1s - loss: 0.024 - ET\n",
      "Epoch 190/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0223\n",
      "Epoch 191/1000\n",
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0227\n",
      "Epoch 192/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0209\n",
      "Epoch 193/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0245\n",
      "Epoch 194/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0220\n",
      "Epoch 195/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0210\n",
      "Epoch 196/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0247\n",
      "Epoch 197/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0219\n",
      "Epoch 198/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0210\n",
      "Epoch 199/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0228\n",
      "Epoch 200/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0218\n",
      "Epoch 201/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0201: 1s - loss: 0.0 - ETA: 1s - lo - ETA: \n",
      "Epoch 202/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0216\n",
      "Epoch 203/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0198: 0s - loss\n",
      "Epoch 204/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0197\n",
      "Epoch 205/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0207\n",
      "Epoch 206/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0202\n",
      "Epoch 207/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0216\n",
      "Epoch 208/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0214\n",
      "Epoch 209/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0210\n",
      "Epoch 210/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0222\n",
      "Epoch 211/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0230\n",
      "Epoch 212/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0207: 2s - \n",
      "Epoch 213/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0202\n",
      "Epoch 214/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0226\n",
      "Epoch 215/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0220\n",
      "Epoch 216/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0190\n",
      "Epoch 217/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0195\n",
      "Epoch 218/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0211: \n",
      "Epoch 219/1000\n",
      "173/173 [==============================] - 4s 25ms/step - loss: 0.0229\n",
      "Epoch 220/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0239\n",
      "Epoch 221/1000\n",
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0200\n",
      "Epoch 222/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0209\n",
      "Epoch 223/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0226\n",
      "Epoch 224/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0194: 0s - loss\n",
      "Epoch 225/1000\n",
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0211\n",
      "Epoch 226/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0223\n",
      "Epoch 227/1000\n",
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0205\n",
      "Epoch 228/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0223\n",
      "Epoch 229/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0206\n",
      "Epoch 230/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0209\n",
      "Epoch 231/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0232\n",
      "Epoch 232/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0213\n",
      "Epoch 233/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0216\n",
      "Epoch 234/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0205: \n",
      "Epoch 235/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0227\n",
      "Epoch 236/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0230\n",
      "Epoch 237/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0214\n",
      "Epoch 238/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0190\n",
      "Epoch 239/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0242\n",
      "Epoch 240/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0234: 1s - loss: \n",
      "Epoch 241/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0208: 1s - loss:\n",
      "Epoch 242/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0197: 0s -\n",
      "Epoch 243/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0214\n",
      "Epoch 244/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0204\n",
      "Epoch 245/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0223\n",
      "Epoch 246/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0251\n",
      "Epoch 247/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0224\n",
      "Epoch 248/1000\n",
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0216\n",
      "Epoch 249/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0196:\n",
      "Epoch 250/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0210\n",
      "Epoch 251/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0211\n",
      "Epoch 252/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0212\n",
      "Epoch 253/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0207\n",
      "Epoch 254/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0231\n",
      "Epoch 255/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0234\n",
      "Epoch 256/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0198\n",
      "Epoch 257/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0218\n",
      "Epoch 258/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0219\n",
      "Epoch 259/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0222\n",
      "Epoch 260/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0206\n",
      "Epoch 261/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0214\n",
      "Epoch 262/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0201\n",
      "Epoch 263/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0201\n",
      "Epoch 264/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0211:\n",
      "Epoch 265/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0228\n",
      "Epoch 266/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0221\n",
      "Epoch 267/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0215\n",
      "Epoch 268/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0217\n",
      "Epoch 269/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0217:  - ETA: 0s - loss: 0.021\n",
      "Epoch 270/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0203\n",
      "Epoch 271/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0208\n",
      "Epoch 272/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0204\n",
      "Epoch 273/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0208\n",
      "Epoch 274/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0223\n",
      "Epoch 275/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0216\n",
      "Epoch 276/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0225\n",
      "Epoch 277/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0229\n",
      "Epoch 278/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0213\n",
      "Epoch 279/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0186\n",
      "Epoch 280/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0199\n",
      "Epoch 281/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0231\n",
      "Epoch 282/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0221\n",
      "Epoch 283/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0195\n",
      "Epoch 284/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0200\n",
      "Epoch 285/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0206\n",
      "Epoch 286/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0228\n",
      "Epoch 287/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0231: 0s - loss:\n",
      "Epoch 288/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0215\n",
      "Epoch 289/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0211\n",
      "Epoch 290/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0203\n",
      "Epoch 291/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0227\n",
      "Epoch 292/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0193\n",
      "Epoch 293/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0206\n",
      "Epoch 294/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0231: 2s - \n",
      "Epoch 295/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0214\n",
      "Epoch 296/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0212\n",
      "Epoch 297/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0215\n",
      "Epoch 298/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0223\n",
      "Epoch 299/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0242\n",
      "Epoch 300/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0225 -\n",
      "Epoch 301/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0230: 0s - loss: \n",
      "Epoch 302/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0232\n",
      "Epoch 303/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0213\n",
      "Epoch 304/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0260\n",
      "Epoch 305/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0216: 1s - loss: - ETA: 1s - ETA: 0s - loss: 0\n",
      "Epoch 306/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0203\n",
      "Epoch 307/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0228\n",
      "Epoch 308/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0219\n",
      "Epoch 309/1000\n",
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0208\n",
      "Epoch 310/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0217\n",
      "Epoch 311/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0211\n",
      "Epoch 312/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0207: 0s - loss: 0.02\n",
      "Epoch 313/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0202\n",
      "Epoch 314/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0207: 0s - loss: \n",
      "Epoch 315/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0185\n",
      "Epoch 316/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0207\n",
      "Epoch 317/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0221\n",
      "Epoch 318/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0225\n",
      "Epoch 319/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0212: 2s - l\n",
      "Epoch 320/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0215: 0s - loss\n",
      "Epoch 321/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0203: 0s - loss: \n",
      "Epoch 322/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0221\n",
      "Epoch 323/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0225: 0s -\n",
      "Epoch 324/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0205\n",
      "Epoch 325/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0205\n",
      "Epoch 326/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0236: 0s - lo\n",
      "Epoch 327/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0196\n",
      "Epoch 328/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0207\n",
      "Epoch 329/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0233\n",
      "Epoch 330/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0211\n",
      "Epoch 331/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0220: 1s - loss: 0.022 - E\n",
      "Epoch 332/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0222\n",
      "Epoch 333/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0228\n",
      "Epoch 334/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0209: 0s - loss: \n",
      "Epoch 335/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0234\n",
      "Epoch 336/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0203\n",
      "Epoch 337/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0215: 0s - loss: 0.0\n",
      "Epoch 338/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0231\n",
      "Epoch 339/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0228\n",
      "Epoch 340/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0200\n",
      "Epoch 341/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0234: 0s - loss: 0.0\n",
      "Epoch 342/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0239\n",
      "Epoch 343/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0204\n",
      "Epoch 344/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0208\n",
      "Epoch 345/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0232\n",
      "Epoch 346/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0209: 0s - loss\n",
      "Epoch 347/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0222\n",
      "Epoch 348/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0210\n",
      "Epoch 349/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0216\n",
      "Epoch 350/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0235\n",
      "Epoch 351/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0212\n",
      "Epoch 352/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0214: 0\n",
      "Epoch 353/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0216\n",
      "Epoch 354/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0229\n",
      "Epoch 355/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0232\n",
      "Epoch 356/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0205\n",
      "Epoch 357/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0209\n",
      "Epoch 358/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0221\n",
      "Epoch 359/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0195\n",
      "Epoch 360/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0212\n",
      "Epoch 361/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0201\n",
      "Epoch 362/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0213\n",
      "Epoch 363/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0191\n",
      "Epoch 364/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0237\n",
      "Epoch 365/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0193\n",
      "Epoch 366/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0204: 0s - loss\n",
      "Epoch 367/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0208\n",
      "Epoch 368/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0212\n",
      "Epoch 369/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0204: 0s - loss: \n",
      "Epoch 370/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0201\n",
      "Epoch 371/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0230\n",
      "Epoch 372/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0213\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0220: 0s\n",
      "Epoch 374/1000\n",
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0210\n",
      "Epoch 375/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0242\n",
      "Epoch 376/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0212\n",
      "Epoch 377/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0220\n",
      "Epoch 378/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0216\n",
      "Epoch 379/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0228\n",
      "Epoch 380/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0213\n",
      "Epoch 381/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0204\n",
      "Epoch 382/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0211\n",
      "Epoch 383/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0215\n",
      "Epoch 384/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0206\n",
      "Epoch 385/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0224\n",
      "Epoch 386/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0206\n",
      "Epoch 387/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0201\n",
      "Epoch 388/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0225\n",
      "Epoch 389/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0206\n",
      "Epoch 390/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0207\n",
      "Epoch 391/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0209\n",
      "Epoch 392/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0212\n",
      "Epoch 393/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0204: 0s - loss: 0.020\n",
      "Epoch 394/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0230\n",
      "Epoch 395/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0225\n",
      "Epoch 396/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0204\n",
      "Epoch 397/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0209\n",
      "Epoch 398/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0230\n",
      "Epoch 399/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0204\n",
      "Epoch 400/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0202\n",
      "Epoch 401/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0228: 0s - loss: 0.02\n",
      "Epoch 402/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0194\n",
      "Epoch 403/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0212\n",
      "Epoch 404/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0221\n",
      "Epoch 405/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0221\n",
      "Epoch 406/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0231\n",
      "Epoch 407/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0228\n",
      "Epoch 408/1000\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0218\n",
      "Epoch 409/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0207\n",
      "Epoch 410/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0224\n",
      "Epoch 411/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0222\n",
      "Epoch 412/1000\n",
      "173/173 [==============================] - 3s 19ms/step - loss: 0.0212\n",
      "Epoch 413/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0210\n",
      "Epoch 414/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0245\n",
      "Epoch 415/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0230\n",
      "Epoch 416/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0189A: 0s - lo\n",
      "Epoch 417/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0211\n",
      "Epoch 418/1000\n",
      "173/173 [==============================] - 4s 20ms/step - loss: 0.0234\n",
      "Epoch 419/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0245\n",
      "Epoch 420/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0221\n",
      "Epoch 421/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0224\n",
      "Epoch 422/1000\n",
      "173/173 [==============================] - 4s 21ms/step - loss: 0.0249: 0s - loss: 0.0\n",
      "Epoch 423/1000\n",
      "173/173 [==============================] - 4s 22ms/step - loss: 0.0227\n",
      "Epoch 424/1000\n",
      "173/173 [==============================] - 4s 23ms/step - loss: 0.0200\n",
      "Epoch 425/1000\n",
      " 73/173 [===========>..................] - ETA: 2s - loss: 0.0194"
     ]
    }
   ],
   "source": [
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "history = regressor.fit(X_train, y_train, epochs = epochs_number, batch_size = batch_size_number)\n",
    "#, callbacks = callbacks\n",
    "# callbacks=[es_callback]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set_sub = test_set\n",
    "test_set_sub = test_set[test_set['container_id']==container_number]\n",
    "#training_set_sub = training_set\n",
    "training_set_sub = training_set[training_set['container_id']==container_number]\n",
    "\n",
    "real_height = test_set_sub.iloc[:, 20:21].values\n",
    "dataset_total = pd.concat((training_set_sub['hight_delta'], test_set_sub['hight_delta']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(test_set_sub) - timelag:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(timelag, len(test_set_sub)+timelag):\n",
    "    X_test.append(inputs[i-timelag:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_height = regressor.predict(X_test)\n",
    "predicted_height = sc.inverse_transform(predicted_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(real_height[100:300], color = 'green', label = 'Real Height')\n",
    "plt.plot(predicted_height[100:300], color = 'red', label = 'Predicted Height')\n",
    "plt.title('Height Prediction with Timelag '+ str(timelag) + ' for container number ' +str(container_number))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Height Delta')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save('../data/modeling/dev/test_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST FOR A SINGLE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"../data/modeling/dev/test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_sub = test_set[test_set['container_id']==1].head(1)\n",
    "training_set_sub = training_set[training_set['container_id']==1]\n",
    "\n",
    "real_height = test_set_sub.iloc[:, 20:21].values\n",
    "dataset_total = pd.concat((training_set_sub['hight_delta'], test_set_sub['hight_delta']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(test_set_sub) - timelag:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(timelag, len(test_set_sub)+timelag):\n",
    "    X_test.append(inputs[i-timelag:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "predicted_height = reconstructed_model.predict(X_test)\n",
    "predicted_height = sc.inverse_transform(predicted_height)\n",
    "\n",
    "print(\"Pred =\"+str(predicted_height)+\" and real height = \"+str(real_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chally_ai",
   "language": "python",
   "name": "chally_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
